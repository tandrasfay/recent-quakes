{
 "metadata": {
  "name": "Recent Earthquakes"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Use [urllib](http://docs.python.org/2/library/urllib.html) to open arbitrary resources by URL and pass that data to the [read_csv](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.parsers.read_csv.html) function of pandas. Then print out the first few rows of data using pandas [Indexing and Selecting Data](http://pandas.pydata.org/pandas-docs/dev/indexing.html)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import urllib\n",
      "from pandas import read_csv\n",
      "\n",
      "\n",
      "url = 'http://earthquake.usgs.gov/earthquakes/catalogs/eqs7day-M1.txt'\n",
      "data = read_csv(urllib.urlopen(url))\n",
      "\n",
      "data[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**UH OH!** Note that our data is a bit *dirty* and contains a notice that this data feed has been deprecated:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print data[0:1]['Src'].values[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can filter out the dirty data using [dropna](http://pandas.pydata.org/pandas-docs/dev/generated/pandas.DataFrame.dropna.html) to drop any rows that contain **NaN**."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "clean_data = data.dropna(axis=0, how='any')\n",
      "clean_data[0:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In the code above note that I saved the results of `data.dropna()` into a different variable `clean_data` rather than over-writing the old variable `data`. **Why?** Why not just re-use old variable names? And if we did re-use old variable names what extra danger do we have to keep in mind while using the IPython Notebook?"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now let's just focus on earthquakes in Alaska (my home state! :)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alaska = clean_data[clean_data.Src == 'ak']\n",
      "alaska[0:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from mpl_toolkits.basemap import Basemap\n",
      "\n",
      "def plot_quakes(quakes):\n",
      "    m = Basemap(llcrnrlon=-180,llcrnrlat=50.,\n",
      "                urcrnrlon=-120.,urcrnrlat=72,\n",
      "                resolution='l',area_thresh=1000.,projection='merc',\n",
      "                lat_0=62.9540,lon_0=-149.2697)\n",
      "    m.drawcoastlines()\n",
      "    m.drawcountries()\n",
      "    m.fillcontinents(color='coral',lake_color='blue')\n",
      "    m.drawmapboundary(fill_color='aqua')\n",
      "    x, y = m(quakes.Lon, quakes.Lat)\n",
      "    m.plot(x, y, 'k.')\n",
      "    return m\n",
      "\n",
      "plot_quakes(alaska)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}